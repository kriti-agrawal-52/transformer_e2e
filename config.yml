# config.yml
# Configuration for Transformer Learning
# --- CONTROL FLAGS ---

SHOULD_TRAIN_SINGLE_RUN: True # Set to true to run the single run (where we have 1 set of hyperparameters)
SHOULD_HYPERPARAMETER_SEARCH: True # Set to true for hyperparameter searching
ALWAYS_LOG_ARTIFACTS: True # Flag for if we want to save our model as wandb artefact

# --- Environment ---
DEVICE: "auto" # "auto", "cuda", or "cpu"

# --- Dataset and Tokenizer ---
DATASET_NAME: "wikitext"
DATASET_VARIANT: "wikitext-2-raw-v1"
TOKENIZER_NAME: "gpt2"

# --- Data Loading Configuration ---
# Set the maximum number of characters to use for training
# This limits the dataset size for faster iteration, especially for tuning.
RAW_TEXT_LIMIT: 50000000 # 50 Million characters

RUN_MODE: "single" # single or grid

# --- TRAINING HYPERPARAMETERS FOR SINGLE RUN TRAINING---
BATCH_SIZE: 16
CONTEXT_WINDOW: 124
CHANNEL_DIM: 384 # 512
NUM_HEADS: 12 # 16
NUM_LAYERS: 8 # 12
LEARNING_RATE: 3e-4 # 5e-4
TRAINING_STEPS: 20000

MIN_DELTA: 0.001 # we should not make this value too small because we want to have meaningful improvement in our validation loss
EVAL_ITERS_VAL: 20 # for calculating evaluation loss, we randomly take EVAL_ITERS_VAL batches of validation set, and take their average loss.
EVAL_ITERS_TEST: 50
VALIDATION_CHECK_EVERY: 100
EARLY_STOPPING_PATIENCE: 25 # 20

# --- TRAINING HYPERPARAMETERS GRID SEARCH FOR HYPERPARAMETER SEARCH ---
HP_SEARCH_LRS: [1e-3, 5e-4, 1e-4]
HP_SEARCH_BATCH_SIZES: [8, 16, 32]
HP_SEARCH_CONTEXT_WINDOWS: [32, 64, 128]

# FIXED HYPERPARAMETERS FOR HYPERPARAMETER SEARCH
HP_SEARCH_STEPS: 5000
HP_VALIDATION_CHECK_EVERY: 25
HP_EARLY_STOPPING_PATIENCE: 10

# --- WANDB CONFIGURATIONS ---
WANDB_PROJECT: "Transformer e2e"
WANDB_RUN_PREFIX:
  - "transformer_e2e_single_run_"
  - "transformer_e2e_sweep_"

# --- PATH FOR SAVING MODEL CHECKPOINTS ---
MODEL_CHECKPOINTS_DIR: "model_checkpoints/" # Path for saving model checkpoints
LOG_FILE: "transformer_epic_model.log" # file to log runs on the codebase
LOSS_PLOT_DIRECTORY: "train_eval_plots/" # directory for loss plots

# --- TEXT GENERATION PARAMETERS ---
MAX_TOKENS_AHEAD: 100
TEMPERATURE: 0.7
TOP_K: 40
